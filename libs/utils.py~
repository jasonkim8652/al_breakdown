import argparse
import random

import math
import numpy as np
import torch
import torch.nn.functional as F

import matplotlib.pyplot as plt
plt.switch_backend('agg')
import cairosvg

from rdkit import Chem
from rdkit.Chem import Draw

from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score


def str2bool(v):
	if v.lower() in ['yes', 'true', 't', 'y', '1']:
		return True
	elif v.lower() in ['no', 'false', 'f', 'n', '0']:
		return False
	else:
		raise argparse.ArgumentTypeError('Boolean value expected')


def set_seed(seed):
	random.seed(seed)
	np.random.seed(seed)
	torch.manual_seed(seed)
	torch.random.manual_seed(seed)

	if torch.cuda.is_available():
		torch.cuda.manual_seed(seed)
		torch.cuda.manual_seed_all(seed)
		torch.backends.cudnn.deterministic = True
		torch.backends.cudnn.benchmark = False


def set_device(
		use_gpu,
		gpu_idx
	):
	if use_gpu:
		device = torch.device('cuda:'+str(gpu_idx))
		print ("PyTorch version:", torch.__version__)
		print ("PyTorch GPU count:", torch.cuda.device_count())
		print ("PyTorch Current GPU:", device)
		print ("PyTorch GPU name:", torch.cuda.get_device_name(device))
		return device
	else:
		device = torch.device('cpu')
		return device


def sigmoid(x):
	return 1./1.+np.exp(-x)


def calibration(
		label, 
		pred, 
		bins=10
	):

	width = 1.0 / bins
	bin_centers = np.linspace(0, 1.0-width, bins) + width/2

	conf_bin = []
	acc_bin = []
	counts = []
	for	i, threshold in enumerate(bin_centers):
		bin_idx = np.logical_and(
			threshold - width/2 < pred, 
			pred <= threshold + width
		)
		conf_mean = pred[bin_idx].mean()
		conf_sum = pred[bin_idx].sum()
		if (conf_mean != conf_mean) == False:
			conf_bin.append(conf_mean)
			counts.append(pred[bin_idx].shape[0])

		acc_mean = label[bin_idx].mean()
		acc_sum = label[bin_idx].sum()
		if (acc_mean != acc_mean) == False:
			acc_bin.append(acc_mean)

	conf_bin = np.asarray(conf_bin)
	acc_bin = np.asarray(acc_bin)
	counts = np.asarray(counts)

	ece = np.abs(conf_bin - acc_bin)
	ece = np.multiply(ece, counts)
	ece = ece.sum()
	ece /= np.sum(counts)
	return conf_bin, acc_bin, ece


def evaluate_classification(
		y_list,
		pred_list,
	):
	y_list = torch.cat(y_list, dim=0).detach().cpu().numpy()
	pred_list = torch.cat(pred_list, dim=0).detach().cpu().numpy()

	auroc = roc_auc_score(y_list, pred_list)
	_, _, ece = calibration(y_list, pred_list)

	'''
	To calculate metric in the below,
	scores should be presented in integer type
	'''
	y_list = y_list.astype(int)
	pred_list = np.around(pred_list).astype(int)

	accuracy = accuracy_score(y_list, pred_list)
	precision = precision_score(y_list, pred_list)
	recall = recall_score(y_list, pred_list)
	f1 = 2.0 * precision * recall / (precision + recall)
	return accuracy, auroc, precision, recall, f1, ece


def evaluate_regression(
		y_list,
		pred_list,
	):
	y_list = torch.cat(y_list, dim=0).detach().cpu().numpy()
	pred_list = torch.cat(pred_list, dim=0).detach().cpu().numpy()

	mse = mean_squared_error(y_list, pred_list)
	rmse = math.sqrt(mse)
	r2 = r2_score(y_list, pred_list)
	return mse, rmse, r2


def heteroscedastic_loss(
		pred,
		y,
	):
	mean = pred[:,0]
	logvar = pred[:,1]
	
	loss_val = torch.exp(-logvar) * (y - mean)**2 + logvar
	loss_val *= 0.5
	loss_val = torch.mean(loss_val, dim=0)
	return loss_val


def plot_attention(
		smi_list,
		id_list,
		dock_list, 
		pred_list,
		unc_list,
		sim_list,
		attention_list,
		prefix,
	):
	pred_list = pred_list.detach().cpu().numpy()
	unc_list = unc_list.detach().cpu().numpy()

	attention_list = attention_list.squeeze()
	attention_list = attention_list.detach().cpu().numpy()
	attention_list = np.mean(attention_list, axis=1)

	mol_list = [Chem.MolFromSmiles(smi) for smi in smi_list]
	legends = []
	for i, mol in enumerate(mol_list):
		num_atoms = mol.GetNumAtoms()
		atom_list = mol.GetAtoms()
		highlight_atoms = []
		highlight_colors = []
		for j, atom in enumerate(atom_list):
			attn_val = round(attention_list[i, j] * num_atoms, 2) 
			atom.SetProp('atomLabel', str(attn_val))
		legend = id_list[i]
		legend += ', ' + str(dock_list[i])
		legend += ', ' + str(round(pred_list[i], 1))
		legend += ', ' + str(round(unc_list[i], 1))
		legend += ', ' + str(round(sim_list[i], 2))
		#legend += 'Pred: ' + str(round(pred_list[i], 2)) + ' '
		#legend += 'Unc: ' + str(round(unc_list[i], 2))
		legends.append(legend)

	img = Draw.MolsToGridImage(
		mol_list,
		molsPerRow=5,
		legends=legends,
		subImgSize=(600,600),
	)
	img.save('./figures/' + prefix + '_attn.png')

def plot_explanation_svg(
		mol,
		radius,
		num_bonds,
		path,
	):
	highlight = [i for i in range(num_bonds)]
	Chem.rdDepictor.Compute2DCoords(mol)
	drawer = Draw.rdMolDraw2D.MolDraw2DSVG(400, 200)
	drawer.DrawMolecule(
		mol
		highlightAtoms=[],
		highlightBonds=highlight,
		highlightBondRadii=radius,
	)
	drawer.FinishDrawing()
	svg = drawer.GetDrawingText().replace('svg:', '')

	f = open('./figures/'+path+'.svg', 'w')	
	f.write(svg)
	f.close()
	cairosvg.svg2png(
		url='./figures/'+path+'.svg',
		write_to='./figures/'+path+'.png'
	)



def plot_attention_svg(
		mol,
		radius,
		num_atoms,
		path,
	):
	highlight = [i for i in range(num_atoms)]
	Chem.rdDepictor.Compute2DCoords(mol)
	drawer = Draw.rdMolDraw2D.MolDraw2DSVG(400, 200)
	drawer.DrawMolecule(
		mol,
		highlightAtoms=highlight,
		highlightAtomRadii=radius,
		highlightBonds=False,
	)
	drawer.FinishDrawing()
	svg = drawer.GetDrawingText().replace('svg:', '')

	f = open('./figures/'+path+'.svg', 'w')
	f.write(svg)
	f.close()
	cairosvg.svg2png(
		url='./figures/'+path+'.svg',
		write_to='./figures/'+path+'.png'
	)


def plot_svg_list(
		smi_list,
		id_list,
		attention_list,
		job_type,
		scale=5.0
	):
	attention_list = attention_list.squeeze()
	attention_list = attention_list.detach().cpu().numpy()
	attention_list = np.mean(attention_list, axis=1)

	mol_list = [Chem.MolFromSmiles(smi) for smi in smi_list]
	legends = []
	if job_type == 'attention':
		for i, mol in enumerate(mol_list):
			num_atoms = mol.GetNumAtoms()
			num_bonds = mol.GetNumBonds()
			atom_list = mol.GetAtoms()
			num_atoms = len(atom_list)
			radius = {}
			for j, atom in enumerate(atom_list):
				attn_val = attention_list[i, j] * num_atoms
				#atom.SetProp('atomLabel', str(round(attn_val, 2)))

				attn_val = attn_val / scale
				radius[j] = attn_val
			path = id_list[i] + '_att_3w2o'
			plot_attention_svg(
				mol=mol,
				radius=radius,
				num_atoms=num_atoms,
				path=path,
			)
	if job_type == 'explainer':
		for i, mol in enumerate(mol_list):
			num_atoms = mol.GetNumAtoms()
			num_bonds = mol.GetNumBonds()
			atom_list = mol.GetAtoms()
			num_atoms = len(atom_list)
			radius = attention_list
			path = id_list[i] + '_exp_3w2o'
			plot_explanation_svg(
				mol=mol,
				radius=radius,
				num_bonds=num_bonds,
				path=path,
			)


